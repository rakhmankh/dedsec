# etl/train.py
import pandas as pd
import joblib
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error
import os

print("üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–≥—Ä–µ–≥–∞—Ç—ã...")
df = pd.read_csv("data/aggregates.csv")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å
expected_features = ["hour", "dayofweek", "lag1", "lag2", "lag3"]
features = [f for f in expected_features if f in df.columns]

if not features:
    raise ValueError("‚ùå –í –∞–≥—Ä–µ–≥–∞—Ç–∞—Ö –Ω–µ—Ç –Ω—É–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤! –ü—Ä–æ–≤–µ—Ä—å preprocess.py")

X, y = df[features], df["count_trips"]

# train/test split (–ø–æ –≤—Ä–µ–º–µ–Ω–∏, –±–µ–∑ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è)
train_size = int(len(df) * 0.8)
X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]
y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]

print(f"üöÄ –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å (–ø—Ä–∏–∑–Ω–∞–∫–∏: {features})...")
model = LGBMRegressor(random_state=42)
model.fit(X_train, y_train)

# –ü—Ä–æ–≥–Ω–æ–∑ –∏ –º–µ—Ç—Ä–∏–∫–∞
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. MAE = {mae:.2f}")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
os.makedirs("data", exist_ok=True)
joblib.dump(model, "data/model.pkl")
print("üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: data/model.pkl")

# –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ "–ø–æ—Å–ª–µ–¥–Ω–∏–π —Å—Ä–µ–∑" (–∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ –±—É–¥—É—â–µ–µ)
latest = df.groupby("h3").tail(1).copy()
latest["predicted"] = model.predict(latest[features])

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑
latest[["h3", "hour", "dayofweek", "count_trips", "predicted"]].to_csv(
    "data/predictions.csv", index=False
)
print("‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: data/predictions.csv")
print(latest.head())
